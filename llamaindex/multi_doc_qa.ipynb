{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index nltk milvus pymilvus langchain openai python-dotenv requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yujiantang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yujiantang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex, \n",
    "    SimpleKeywordTableIndex, \n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    StorageContext\n",
    ")\n",
    "from langchain.llms.openai import OpenAIChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from llama_index.vector_stores import MilvusVectorStore\n",
    "from milvus import default_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_server.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dim argument required for collection creation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yujiantang/Documents/workspace/hello_world_project/llamaindex/multi_doc_qa.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yujiantang/Documents/workspace/hello_world_project/llamaindex/multi_doc_qa.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vector_store \u001b[39m=\u001b[39m MilvusVectorStore(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yujiantang/Documents/workspace/hello_world_project/llamaindex/multi_doc_qa.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m    host \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mlocalhost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yujiantang/Documents/workspace/hello_world_project/llamaindex/multi_doc_qa.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m    port \u001b[39m=\u001b[39;49m default_server\u001b[39m.\u001b[39;49mlisten_port\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yujiantang/Documents/workspace/hello_world_project/llamaindex/multi_doc_qa.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/workspace/hello_world_project/hw_milvus/lib/python3.10/site-packages/llama_index/vector_stores/milvus.py:133\u001b[0m, in \u001b[0;36mMilvusVectorStore.__init__\u001b[0;34m(self, uri, token, collection_name, dim, embedding_field, doc_id_field, similarity_metric, consistency_level, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollection_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mlist_collections():\n\u001b[1;32m    132\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDim argument required for collection creation.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmilvusclient\u001b[39m.\u001b[39mcreate_collection(\n\u001b[1;32m    135\u001b[0m         collection_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollection_name,\n\u001b[1;32m    136\u001b[0m         dimension\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m         consistency_level\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconsistency_level,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    145\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSuccessfully created a new collection: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollection_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Dim argument required for collection creation."
     ]
    }
   ],
   "source": [
    "vector_store = MilvusVectorStore(\n",
    "   host = \"localhost\",\n",
    "   port = default_server.listen_port\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles = [\"Toronto\", \"Seattle\", \"San Francisco\", \"Chicago\", \"Boston\", \"Washington, D.C.\", \"Cambridge, Massachusetts\", \"Houston\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "for title in wiki_titles:\n",
    "    response = requests.get(\n",
    "        'https://en.wikipedia.org/w/api.php',\n",
    "        params={\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'titles': title,\n",
    "            'prop': 'extracts',\n",
    "            # 'exintro': True,\n",
    "            'explaintext': True,\n",
    "        }\n",
    "    ).json()\n",
    "    page = next(iter(response['query']['pages'].values()))\n",
    "    wiki_text = page['extract']\n",
    "\n",
    "    data_path = Path('data')\n",
    "    if not data_path.exists():\n",
    "        Path.mkdir(data_path)\n",
    "\n",
    "    with open(data_path / f\"{title}.txt\", 'w') as fp:\n",
    "        fp.write(wiki_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all wiki documents\n",
    "city_docs = {}\n",
    "for wiki_title in wiki_titles:\n",
    "    city_docs[wiki_title] = SimpleDirectoryReader(input_files=[f\"data/{wiki_title}.txt\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yujiantang/Documents/workspace/hello_world_project/hw_milvus/lib/python3.10/site-packages/langchain/llms/openai.py:786: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1007)>\n"
     ]
    }
   ],
   "source": [
    "llm_predictor_chatgpt = LLMPredictor(llm=OpenAIChat(temperature=0, model_name=\"gpt-3.5-turbo\"))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build city document index\n",
    "city_indices = {}\n",
    "index_summaries = {}\n",
    "for wiki_title in wiki_titles:\n",
    "    city_indices[wiki_title] = VectorStoreIndex.from_documents(city_docs[wiki_title], service_context=service_context, storage_context=storage_context)\n",
    "    # set summary text for city\n",
    "    index_summaries[wiki_title] = f\"Wikipedia articles about {wiki_title}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.composability import ComposableGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ComposableGraph.from_indices(\n",
    "    SimpleKeywordTableIndex,\n",
    "    [index for _, index in city_indices.items()], \n",
    "    [summary for _, summary in index_summaries.items()],\n",
    "    max_keywords_per_chunk=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.query.query_transform.base import DecomposeQueryTransform\n",
    "decompose_transform = DecomposeQueryTransform(\n",
    "    llm_predictor_chatgpt, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine.transform_query_engine import TransformQueryEngine\n",
    "custom_query_engines = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in city_indices.values():\n",
    "    query_engine = index.as_query_engine(service_context=service_context)\n",
    "    transform_extra_info = {'index_summary': index.index_struct.summary}\n",
    "    tranformed_query_engine = TransformQueryEngine(query_engine, decompose_transform, transform_metadata=transform_extra_info)\n",
    "    custom_query_engines[index.index_id] = tranformed_query_engine\n",
    "\n",
    "custom_query_engines[graph.root_index.index_id] = graph.root_index.as_query_engine(\n",
    "    retriever_mode='simple', \n",
    "    response_mode='tree_summarize', \n",
    "    service_context=service_context\n",
    ")\n",
    "\n",
    "query_engine_decompose = graph.as_query_engine(\n",
    "    custom_query_engines=custom_query_engines,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_chatgpt = query_engine_decompose.query(\n",
    "    \"Compare and contrast the airports in Seattle and Houston. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response_chatgpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_query_engines = {}\n",
    "for index in city_indices.values():\n",
    "    query_engine = index.as_query_engine(service_context=service_context)\n",
    "    custom_query_engines[index.index_id] = query_engine\n",
    "\n",
    "custom_query_engines[graph.root_index.index_id] = graph.root_index.as_query_engine(\n",
    "    retriever_mode='simple', \n",
    "    response_mode='tree_summarize', \n",
    "    service_context=service_context\n",
    ")\n",
    "\n",
    "query_engine = graph.as_query_engine(\n",
    "    custom_query_engines=custom_query_engines,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_chatgpt = query_engine.query(\n",
    "    \"Compare and contrast the airports in Seattle and Houston. \"\n",
    ")\n",
    "str(response_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_chatgpt = query_engine_decompose.query(\n",
    "    \"Compare and contrast the sports environment of Houston and Boston. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(response_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import utility, connections\n",
    "\n",
    "connections.connect(host=\"127.0.0.1\", port=default_server.listen_port)\n",
    "for collection in utility.list_collections():\n",
    "    utility.drop_collection(collection)\n",
    "\n",
    "default_server.stop()\n",
    "default_server.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw_milvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
